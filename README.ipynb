{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile README.md\n",
    "# Road Semantic Segmentation\n",
    "---\n",
    "This project is an implementation of Fully Convolutional Network for road semantic segmentation by labeling the road pixels in Image.\n",
    "\n",
    "---\n",
    "## Project Objectives\n",
    "1. Extracting pretrained VGG-16 feature encoder.\n",
    "2. Implementing FCN-8 decoder\n",
    "3. Data Augmentation\n",
    "4. Train the model on Kitti Road dataset \n",
    "5. Apllying the model to test data\n",
    "6. Applying the model to Video\n",
    "---\n",
    "[image1]: ./runs/Images_results/loss_plot.png\n",
    "[image2]: ./runs/Images_results/combined.png\n",
    "\n",
    "## Data Augmentation\n",
    "two technique for data augmentation. the first one is to flip the training data set from left to right. the second one is brightness augmentation by converting image to HSV and then scaling up or down the V channel randomly with a factor of 0.25. This was implemented in the gen_batch_function() in helper.py.\n",
    "\n",
    "## Network Architecture\n",
    "\n",
    "A pre-trained VGG-16 network model was used a an encoder by extracting the input, keep probability, layer3, layer4, layer7. The model was converted to FCN-8 by adding decoder network as following:\n",
    "1. 1x1 convolution layer from VDD's layer7\n",
    "2. 1x1 convolution layer from VDD's layer4\n",
    "3. 1x1 convolution layer from VDD's layer3\n",
    "4. Upsampling 1x1 layer7 with kernel 4 and strid 2\n",
    "5. skip layer for 1x1 layer4 and upsamled the layer above\n",
    "6. upsampling 1x1 layer4 with kernel 4 and strid 2\n",
    "7. skip layer for 1x1 layer3 and upsamled the layer above\n",
    "8. upsamling above layer with kernel 16 and stride 8\n",
    "\n",
    "### Hyperparameters\n",
    "1. random-normal kernel initializer with standard deviation 0.01 in all convolutional and upsampling layer\n",
    "2. L2 kernel regularizer with L2 0.001 in all convolutional and upsampling layer\n",
    "3. Epoch=60\n",
    "4. Batch size= 5\n",
    "5. Keep probabilites = .4\n",
    "6. Learning rate= .0001\n",
    "\n",
    "### Optimizer\n",
    "The loss function for the network is cross-entropy, and oprimizer used is Adam optimizer.\n",
    "\n",
    "## Result\n",
    "![title][image1]\n",
    "![title][image2]\n",
    "Here's a [link to my video result1](./result1.mp4) \n",
    "Here's a [link to my video result2](./result2.mp4) \n",
    "Here's a [link to my video result3](./result3.mp4) \n",
    "\n",
    "## Dependencies\n",
    "* Python 3\n",
    "* TensorFlow\n",
    "* NumPy\n",
    "* SciPy\n",
    "* OpenCV\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
